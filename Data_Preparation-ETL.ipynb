{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the pre construct of the ETL of the main database\n",
    "\n",
    "Importing the libraries needed and the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    '''loads the message and categories dataframes'''\n",
    "    \n",
    "    messages = pd.read_csv('data/disaster_messages.csv')\n",
    "    categories_df = pd.read_csv('data/disaster_categories.csv')\n",
    "    \n",
    "    return messages, categories_df\n",
    "\n",
    "messages, categories_df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_numbers(cell):\n",
    "    '''takes an array, cell, and cleans all the non alphanumeric character,\n",
    "    transforms them into a list of integers and returns that list\n",
    "    '''\n",
    "    \n",
    "    cleaned_cell = re.sub(r'[a-zA-Z_-]+', '', cell)\n",
    "    cleaned_cell = list(map(int,cleaned_cell.split(';')))\n",
    "    return cleaned_cell\n",
    "\n",
    "def cleaning_categories(df,column):\n",
    "    '''takes in a dataframe where a column is composed by words followed by numbers,\n",
    "    and transforms it into a dataframe where the words(first row only) are the columns and the numbers are in\n",
    "    the rows of the respective columns\n",
    "    Also removes the words who have a zero count, that is the number which followed it was always zero.\n",
    "    \n",
    "    column - column to clean (string)\n",
    "    df - dataframe to clean\n",
    "    '''\n",
    "    \n",
    "    #reading the first row of the dataframe and transforming into an array of words\n",
    "    column_features = re.sub(r\"[-01;]\", \" \",df[column][0])\n",
    "    column_features = word_tokenize(column_features )\n",
    "    \n",
    "    #creating a temporary dataframe to remove the words and keep the numbers and transform it into a list of lists\n",
    "    temp_df = df[column]\n",
    "    fill_df = []    \n",
    "    for i in range (0,len(temp_df)):    \n",
    "        fill_df.append(only_numbers(temp_df[i]))\n",
    "      \n",
    "    #creating the new dataframe with the expected result\n",
    "    new_df = pd.DataFrame(np.array(fill_df), columns=[column_features])\n",
    "    \n",
    "    #removing the features with only zeros\n",
    "    new_df = new_df.loc[:,new_df.sum(axis=0)>0]\n",
    "    \n",
    "    #removing the rows with all zero values\n",
    "    new_df = new_df[new_df.sum(axis=1) > 0]\n",
    "    \n",
    "    #removing the rows where the features are different than 0 or 1\n",
    "    new_df = new_df[(new_df.iloc[:,0] == 0) | (new_df.iloc[:,0] == 1)]\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "cleaned_categories = cleaning_categories(categories_df,'categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparation(messages,cleaned_categories):\n",
    "    '''takes care of the merging process and final clean up of the dataframes\n",
    "    '''\n",
    "    #merging the two dataframes\n",
    "    df = messages.merge(cleaned_categories,left_index=True, right_index=True)\n",
    "    \n",
    "    #fixing column names\n",
    "    df.rename(columns=lambda col: ''.join(col), inplace=True)\n",
    "    \n",
    "    #dropping the columns that will not be used\n",
    "    df = df.drop(columns=['id','original'])\n",
    "    \n",
    "    #creating dummies from the genre column\n",
    "    df = pd.get_dummies(df,columns=['genre'],drop_first=True)\n",
    "    \n",
    "    # dropping duplicate rows \n",
    "    df.drop_duplicates(keep=False,inplace=True) \n",
    "    \n",
    "    return df\n",
    "\n",
    "df = preparation(messages,cleaned_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data(df):\n",
    "    '''exports the cleaned dataframe to a SQL database'''\n",
    "    \n",
    "    database_name = 'Messages'\n",
    "    connection = database_name+'.db'\n",
    "    #opening connection and cursor\n",
    "    conn = sqlite3.connect(connection)\n",
    "    c = conn.cursor()\n",
    "    conn.commit()\n",
    "    \n",
    "    #transforming the dataframe to a sql database\n",
    "    df.to_sql(database_name, conn, if_exists=\"replace\")\n",
    "    \n",
    "    #closing connections\n",
    "    c.close()\n",
    "    conn.close()\n",
    "\n",
    "export_data(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
